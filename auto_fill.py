import os
import time
import requests
import json
import uuid
from io import BytesIO
from datetime import datetime, timezone, timedelta
from PIL import Image
import re
import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv

# ğŸ›¡ï¸ å¦ƒçˆ±çš„æå®¢ç»ˆææ­¦è£…ï¼šæŠ›å¼ƒç³»ç»Ÿï¼Œå¼ºè¡Œç»‘å®šæ¢¯å­çœŸå®ç«¯å£ï¼
# ğŸ‘‡ æ¬§å°¼é…±ï¼è¯·æŠŠä¸‹é¢çš„ 7897 æ¢æˆä½ åˆšæ‰åœ¨è½¯ä»¶é‡Œçœ‹åˆ°çš„çœŸå®ç«¯å£æ•°å­—ï¼
PROXY_PORT = "62686"  

os.environ['HTTP_PROXY'] = f"http://127.0.0.1:{PROXY_PORT}"
os.environ['HTTPS_PROXY'] = f"http://127.0.0.1:{PROXY_PORT}"
os.environ['ALL_PROXY'] = f"socks5://127.0.0.1:{PROXY_PORT}"

print(f"ğŸ”— å¦ƒçˆ±å·²å¼ºè¡Œå°†å¼•æ“æ¥ç®¡è‡³ä»£ç†ç«¯å£: {PROXY_PORT}")

# ğŸ‘‘ åŠ è½½æ¬§å°¼é…±çš„èµ›åšå¯†é’¥åº“
load_dotenv()

NOTION_TOKEN = os.getenv("NOTION_TOKEN")
print(f"ğŸ•µï¸ ä¾¦æµ‹ Token çŠ¶æ€: {NOTION_TOKEN}")
DATABASE_ID = os.getenv("DATABASE_ID")
TMDB_API_KEY = os.getenv("TMDB_API_KEY")
BANGUMI_USERNAME = os.getenv("BANGUMI_USERNAME")
STEAM_API_KEY = os.getenv("STEAM_API_KEY")
STEAM_IDS = [sid.strip() for sid in os.getenv("STEAM_IDS", "").split(",")] if os.getenv("STEAM_IDS") else []

R2_ACCOUNT_ID = os.getenv("R2_ACCOUNT_ID")
R2_BUCKET_NAME = os.getenv("R2_BUCKET_NAME")
R2_PUBLIC_DOMAIN = os.getenv("R2_PUBLIC_DOMAIN", "").rstrip("/")

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}

# ğŸŒŒ ç»å¯¹æ—¶ç©ºé”šç‚¹ (ä¸œå…«åŒºï¼šæ–°åŠ å¡/åŒ—äº¬æ—¶é—´)
TZ_8 = timezone(timedelta(hours=8))

# ==========================================
# ğŸ›¡ï¸ æå®¢æŸ”æœ¯ï¼šNotion API æŠ—ç†”æ–­è¯·æ±‚åŒ…è£…å™¨
# ==========================================
def safe_notion_request(method, url, json_data=None):
    max_retries = 5
    for attempt in range(max_retries):
        try:
            res = requests.request(method, url, headers=HEADERS, json=json_data, timeout=15)
            if res.status_code == 429:
                sleep_time = 2 ** attempt
                print(f"    âš ï¸ è§¦å‘ Notion é™æµï¼Œé€€é¿ä¼‘çœ  {sleep_time} ç§’...")
                time.sleep(sleep_time)
                continue
            return res
        except requests.exceptions.RequestException as e:
            print(f"    âš ï¸ ç½‘ç»œæ³¢åŠ¨ ({e})ï¼Œæ­£åœ¨é‡è¯•...")
            time.sleep(2)
    return None

# ==========================================
# ğŸ–¼ï¸ R2 å›¾åƒå‹ç¼©ç›´ä¼ å¼•æ“
# ==========================================
def upload_cover_to_r2(image_url, item_id):
    if not image_url or not R2_ACCOUNT_ID: return image_url
    print("    ğŸ¨ å¯åŠ¨ R2 å›¾åƒå¼•æ“ï¼Œå¼€å§‹å‹ç¼©ä¸ç›´ä¼ ...")
    try:
        s3 = boto3.client('s3',
            endpoint_url=f"https://{R2_ACCOUNT_ID}.r2.cloudflarestorage.com",
            aws_access_key_id=os.getenv("R2_ACCESS_KEY"),
            aws_secret_access_key=os.getenv("R2_SECRET_KEY"),
            region_name="auto"
        )
        
        res = requests.get(image_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        if res.status_code != 200: return image_url
        
        img = Image.open(BytesIO(res.content))
        if img.mode in ("RGBA", "P"): img = img.convert("RGB")
        
        webp_buffer = BytesIO()
        img.save(webp_buffer, format="WEBP", quality=85)
        webp_buffer.seek(0)
        
        file_key = f"covers/cov_{item_id}_{uuid.uuid4().hex[:6]}.webp"
        s3.put_object(Bucket=R2_BUCKET_NAME, Key=file_key, Body=webp_buffer, ContentType='image/webp')
        
        final_url = f"{R2_PUBLIC_DOMAIN}/{file_key}"
        print(f"    âœ¨ R2 è½¬åŒ–æˆåŠŸ: {final_url}")
        return final_url
    except Exception as e:
        print(f"    âŒ R2 å¤„ç†å¤±è´¥ ({e})ï¼Œé™çº§ä½¿ç”¨åŸå›¾é“¾æ¥ã€‚")
        return image_url

# ==========================================
# ğŸ“¡ ä¸‰å¤§å¹³å°æ¢æµ‹å™¨ (å…¨é‡æ¦¨å–ç‰ˆ)
# ==========================================
def fetch_bangumi_full(bgm_id):
    result = {}
    res = requests.get(f"https://api.bgm.tv/v0/subjects/{bgm_id}", headers={'User-Agent': 'sandleft/auto-sync'}, timeout=10)
    if res.status_code != 200: return None
    data = res.json()
    
    # --- è¯·åœ¨è¿™ä¸ªä½ç½®æ’å…¥ä»¥ä¸‹ä»£ç  ---
    language_name = ""
    for info in data.get("infobox", []):
        if info.get("key") in ["è¯­è¨€", "è¯­ç§"]:
            language_name = info.get("value", "")
            break
            
    result.update({
        "title": data.get("name_cn") or data.get("name"),
        "cover_raw": data.get("images", {}).get("large", ""),
        "summary": (data.get("summary") or "")[:2000],
        "score_public": data.get("rating", {}).get("score", 0),
        "year": data.get("date", "")[:4] if data.get("date") else "",
        "language": language_name # ğŸ‘ˆ æ–°å¢è¿™ä¸€è¡Œï¼
    })

    if BANGUMI_USERNAME:
        res_user = requests.get(f"https://api.bgm.tv/v0/users/{BANGUMI_USERNAME}/collections/{bgm_id}", headers={'User-Agent': 'sandleft/auto-sync'}, timeout=10)
        if res_user.status_code == 200:
            ud = res_user.json()
            result["score_geek"] = ud.get("rate", 0)
            result["review"] = ud.get("comment", "")
            result["tags"] = ud.get("tags", [])
            status_map = {1: "æƒ³çœ‹", 2: "å·²å®Œæˆ", 3: "è¿›è¡Œä¸­", 4: "æç½®", 5: "æŠ›å¼ƒ"}
            result["status"] = status_map.get(ud.get("type"), "")
            if ud.get("updated_at"):
                result["play_date"] = ud.get("updated_at").split("T")[0]
    return result

def fetch_steam_full(app_id):
    result = {}
    res_info = requests.get(f"https://store.steampowered.com/api/appdetails?appids={app_id}&l=schinese", timeout=10)
    if res_info.status_code != 200: return None
    data = res_info.json()
    if not (data and str(app_id) in data and data[str(app_id)].get("success")): return None
    
    game_data = data[str(app_id)]["data"]
    
    # æå–å¼€å‘è€…ä¸å‘è¡Œå•†å¡«å…¥22åˆ—è¡¨æ ¼
    devs = ", ".join(game_data.get("developers", []))
    pubs = ", ".join(game_data.get("publishers", []))
    
    # --- è¯·åœ¨è¿™ä¸ªä½ç½®æ’å…¥ä»¥ä¸‹ä»£ç  ---
    raw_lang = game_data.get("supported_languages", "")
    clean_lang = re.sub(r'<[^>]+>', '', raw_lang) # æå®¢æ–©ï¼šåˆ‡ç¢æ‰€æœ‰ HTML æ ‡ç­¾
    lang_list = [l.strip() for l in clean_lang.split(',')]
    language_name = ", ".join(lang_list[:3]) if lang_list else "" # åªå–å‰3ç§è¯­è¨€ï¼Œé˜²æ­¢è¡¨æ ¼å¡çˆ†
    
    result.update({
        "title": game_data.get("name"),
        "cover_raw": game_data.get("header_image", "").split("?")[0],
        "summary": (game_data.get("short_description") or "")[:2000],
        "year": game_data.get("release_date", {}).get("date", "")[-4:] if game_data.get("release_date") else "",
        "author": devs[:50],  
        "publisher": pubs[:50], 
        "language": language_name # ğŸ‘ˆ æ–°å¢è¿™ä¸€è¡Œï¼
    })
    
    res_reviews = requests.get(f"https://store.steampowered.com/appreviews/{app_id}?json=1&language=all&purchase_type=all", timeout=10)
    if res_reviews.status_code == 200:
        rev = res_reviews.json().get("query_summary", {})
        if rev.get("total_reviews", 0) > 0:
            result["score_public"] = round((rev["total_positive"] / rev["total_reviews"]) * 10, 1)
            result["steam_review_desc"] = rev.get("review_score_desc", "")

    if STEAM_API_KEY and STEAM_IDS:
        for sid in STEAM_IDS:
            res_play = requests.get(f"http://api.steampowered.com/IPlayerService/GetOwnedGames/v0001/?key={STEAM_API_KEY}&steamid={sid}&format=json", timeout=10)
            if res_play.status_code == 200:
                games = res_play.json().get("response", {}).get("games", [])
                target_game = next((g for g in games if str(g.get("appid")) == str(app_id)), None)
                if target_game:
                    playtime_hours = round(target_game.get("playtime_forever", 0) / 60, 1)
                    result["time_spent"] = f"{playtime_hours} å°æ—¶"
                    
                    last_played_unix = target_game.get("rtime_last_played", 0)
                    if last_played_unix > 0:
                        # å¼ºåˆ¶ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´ï¼Œæœç»äº‘ç«¯éƒ¨ç½²æ—¶çš„æ—¶åŒºæ¼‚ç§»ï¼
                        result["play_date"] = datetime.fromtimestamp(last_played_unix, TZ_8).strftime('%Y-%m-%d')
                    print(f"    ğŸ® æˆªè· Steam æ—¶é•¿ (è´¦å·å°¾å· {sid[-4:]}): {playtime_hours} å°æ—¶")
                    break
    return result

def fetch_tmdb(tmdb_id, media_type="movie"):
    # é¢å¤–æŠ“å– credits æ¼”èŒå‘˜è¡¨
    url = f"https://api.themoviedb.org/3/{media_type}/{tmdb_id}?api_key={TMDB_API_KEY}&language=zh-CN&append_to_response=credits"
    res = requests.get(url, timeout=10)
    if res.status_code != 200: return None
    data = res.json()
    
    date_key = "release_date" if media_type == "movie" else "first_air_date"
    poster = data.get("poster_path")
    
    # è§£æå¯¼æ¼”ä¸ç¬¬ä¸€ä¸»æ¼”
    crew = data.get("credits", {}).get("crew", [])
    director = next((c["name"] for c in crew if c["job"] == "Director"), "")
    cast = data.get("credits", {}).get("cast", [])
    main_actor = cast[0]["name"] if cast else ""

    # --- è¯·åœ¨è¿™ä¸ªä½ç½®æ’å…¥ä»¥ä¸‹ä»£ç  ---
    lang_map = {'en': 'è‹±è¯­', 'ja': 'æ—¥è¯­', 'zh': 'æ±‰è¯­', 'ko': 'éŸ©è¯­', 'fr': 'æ³•è¯­', 'de': 'å¾·è¯­', 'ru': 'ä¿„è¯­'}
    orig_lang = data.get("original_language", "")
    language_name = lang_map.get(orig_lang, orig_lang.upper())
    
    return {
        "title": data.get("title") if media_type == "movie" else data.get("name"),
        "cover_raw": f"https://image.tmdb.org/t/p/w600_and_h900_bestv2{poster}" if poster else "",
        "summary": (data.get("overview") or "")[:2000],
        "score_public": round(data.get("vote_average", 0), 1),
        "year": data.get(date_key, "")[:4] if data.get(date_key) else "",
        "author": main_actor[:50], 
        "publisher": director[:50],
        "language": language_name # ğŸ‘ˆ æ–°å¢è¿™ä¸€è¡Œï¼
    }
    
# ==========================================
# ğŸ§  æ ¸å¿ƒæ¶æ„ï¼šæ¸¸æ ‡åˆ†é¡µä¸æ•°æ®ç»„è£…
# ==========================================
def run_auto_fill():
    print("ğŸš€ å¦ƒçˆ±çš„ R2 ç›´ä¼  & ä¸‡è±¡å¼•åŠ›å¼•æ“ 3.1 (ç»ˆæå®Œæ•´ç‰ˆ) å¯åŠ¨ï¼")
    
    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    filter_data = {
        "filter": {
            "and": [
                { "property": "é‡‡é›†ID", "rich_text": { "is_not_empty": True } },
                { "property": "ç±»åˆ«", "select": { "is_not_empty": True } },
                {
                    "or": [
                        { "property": "ç®€ä»‹", "rich_text": { "is_empty": True } },
                        { "property": "å¼ºåˆ¶åˆ·æ–°", "checkbox": { "equals": True } }
                    ]
                }
            ]
        }
    }
    
    pages, has_more, next_cursor = [], True, None
    while has_more:
        payload = filter_data.copy()
        if next_cursor: payload["start_cursor"] = next_cursor
        res = safe_notion_request("POST", query_url, json_data=payload)
        if not res or res.status_code != 200:
            print(f"âŒ è¯»å– Notion å¤±è´¥ï¼çŠ¶æ€ç : {res.status_code if res else 'ç½‘ç»œç‰©ç†æ–­å¼€'}, è¯¦æƒ…: {res.text if res else 'æ— '}")
            return
        data = res.json()
        pages.extend(data.get("results", []))
        has_more = data.get("has_more", False)
        next_cursor = data.get("next_cursor")

    if not pages:
        print("âœ… æ‰«æå®Œæ¯•ï¼æš‚æ— éœ€è¦å¤„ç†çš„æ¡£æ¡ˆã€‚")
        return

    print(f"ğŸ¯ å…±é”å®š {len(pages)} æ¡å¾…å¤„ç†æ¡£æ¡ˆï¼Œå¼€å§‹ä½œä¸š...")

    for page in pages:
        page_id = page["id"]
        props = page["properties"]
        
        item_id = props["é‡‡é›†ID"]["rich_text"][0]["plain_text"].strip()
        category = props["ç±»åˆ«"]["select"]["name"].strip()
        is_force_refresh = props.get("å¼ºåˆ¶åˆ·æ–°", {}).get("checkbox", False)
        
        print(f"\n[{category}] ID: {item_id} {'(å¼ºåˆ¶åˆ·æ–°)' if is_force_refresh else ''}")
        
        fetched_data = None
        try:
            if category in ["åŠ¨ç”»", "æ¼«ç”»", "galgame", "å›¾ä¹¦", "åŠ¨æ¼«"]: fetched_data = fetch_bangumi_full(item_id)
            elif category == "ç”µå½±": fetched_data = fetch_tmdb(item_id, "movie")
            elif category in ["ç”µè§†å‰§", "æ—¥å‰§", "ç¾å‰§"]: fetched_data = fetch_tmdb(item_id, "tv")
            elif category in ["æ¸¸æˆ", "å•æœºæ¸¸æˆ"]: fetched_data = fetch_steam_full(item_id)
            else: continue
        except Exception as e:
            print(f"    âŒ æ¢æµ‹å¼‚å¸¸: {e}")
            continue

        if not fetched_data:
            print("    âŒ æ¢æµ‹å™¨ç©ºæ‰‹è€Œå½’ã€‚")
            continue
            
        final_cover_url = upload_cover_to_r2(fetched_data.get("cover_raw"), item_id)
        update_props = { "properties": {} }
        
        # åŸºç¡€æ ¡éªŒä¸å†™å…¥
        if not props.get("åç§°", {}).get("title") and fetched_data.get("title"):
            update_props["properties"]["åç§°"] = {"title": [{"text": {"content": fetched_data["title"]}}]}
            
        if final_cover_url: update_props["properties"]["å°é¢"] = {"url": final_cover_url}
        if fetched_data.get("summary"): update_props["properties"]["ç®€ä»‹"] = {"rich_text": [{"text": {"content": fetched_data["summary"]}}]}
        if fetched_data.get("year"): update_props["properties"]["å¹´ä»½"] = {"rich_text": [{"text": {"content": fetched_data["year"]}}]}
        if fetched_data.get("score_public", 0) > 0: update_props["properties"]["å¤§ä¼—è¯„åˆ†"] = {"number": fetched_data["score_public"]}
        # æŠŠè¿™æ®µåŠ åœ¨å±æ€§èµ‹å€¼çš„åŒºåŸŸé‡Œ
        if fetched_data.get("language") and not props.get("è¯­è¨€", {}).get("rich_text"): 
            update_props["properties"]["è¯­è¨€"] = {"rich_text": [{"text": {"content": fetched_data["language"]}}]}
        
        # ä¸»åˆ›å…ƒæ•°æ®è¡¥å…¨ (å……åˆ†åˆ©ç”¨ 22 åˆ—)
        if fetched_data.get("author") and not props.get("ä½œè€…/ä¸»æ¼”", {}).get("rich_text"): 
            update_props["properties"]["ä½œè€…/ä¸»æ¼”"] = {"rich_text": [{"text": {"content": fetched_data["author"]}}]}
        if fetched_data.get("publisher") and not props.get("å‘è¡Œ/å¯¼æ¼”", {}).get("rich_text"): 
            update_props["properties"]["å‘è¡Œ/å¯¼æ¼”"] = {"rich_text": [{"text": {"content": fetched_data["publisher"]}}]}

        # ç§äººæ•°æ®å†™å…¥
        if fetched_data.get("score_geek", 0) > 0: update_props["properties"]["æˆ‘çš„è¯„åˆ†"] = {"number": fetched_data["score_geek"]}
        if fetched_data.get("review"): update_props["properties"]["ç®€è¯„/ç®´è¨€"] = {"rich_text": [{"text": {"content": fetched_data["review"]}}]}
        if fetched_data.get("status"): update_props["properties"]["çŠ¶æ€"] = {"select": {"name": fetched_data["status"]}}
        if fetched_data.get("time_spent"): update_props["properties"]["æ—¶é•¿"] = {"rich_text": [{"text": {"content": fetched_data["time_spent"]}}]}
        
        # æ ‡ç­¾æ¸…æ´—ï¼šä¸¥æ ¼å‰”é™¤é€—å·ä¸ç©ºå€¼
        if fetched_data.get("tags"): 
            clean_tags = [str(t).replace(",", "-").strip()[:20] for t in fetched_data["tags"] if str(t).strip()]
            update_props["properties"]["ç»†åŒ–æ ‡ç­¾"] = {"multi_select": [{"name": t} for t in clean_tags[:10]]}
            
        if fetched_data.get("play_date"): 
            update_props["properties"]["æ—¶é—´"] = {"date": {"start": fetched_data["play_date"]}}

        update_props["properties"]["å¼ºåˆ¶åˆ·æ–°"] = {"checkbox": False}

        # æäº¤åˆ° Notion
        res = safe_notion_request("PATCH", f"https://api.notion.com/v1/pages/{page_id}", json_data=update_props)
        if res and res.status_code == 200:
            print(f"    âœ¨ å®Œç¾å½’æ¡£ï¼ã€Š{fetched_data.get('title')}ã€‹å…¥åº“ã€‚")
            
            # å¢é‡è¿½åŠ  Steam å¥½è¯„ç‡å—
            steam_desc = fetched_data.get("steam_review_desc")
            if steam_desc and not is_force_refresh:
                block_data = {
                    "children": [{
                        "object": "block",
                        "type": "callout",
                        "callout": {
                            "rich_text": [{"type": "text", "text": {"content": f"Steam çœŸå®å—ä¼—åé¦ˆï¼šã€{steam_desc}ã€‘({fetched_data.get('score_public')} åˆ†)ã€‚"}}],
                            "icon": {"type": "emoji", "emoji": "ğŸ‘¾"}
                        }
                    }]
                }
                safe_notion_request("PATCH", f"https://api.notion.com/v1/blocks/{page_id}/children", json_data=block_data)
        else:
            print(f"    âŒ Notion æ³¨å…¥å¤±è´¥: {res.text if res else 'Timeout'}")
            
        time.sleep(1)

if __name__ == "__main__":
    run_auto_fill()